{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "986df2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('data/cleaned_student_depression_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2bd0a5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Visakhapatnam' 'Bangalore' 'Srinagar' 'Varanasi' 'Jaipur' 'Pune' 'Thane'\n",
      " 'Chennai' 'Nagpur' 'Nashik' 'Vadodara' 'Kalyan' 'Rajkot' 'Ahmedabad'\n",
      " 'Kolkata' 'Mumbai' 'Lucknow' 'Indore' 'Surat' 'Ludhiana' 'Bhopal'\n",
      " 'Meerut' 'Agra' 'Ghaziabad' 'Hyderabad' 'Vasai-Virar' 'Kanpur' 'Patna'\n",
      " 'Faridabad' 'Delhi' 'Unknown']\n"
     ]
    }
   ],
   "source": [
    "# print(df['Degree'].unique())\n",
    "print(df['City'].unique())\n",
    "\n",
    "degree_category_map = {\n",
    "    \"Class 12\": \"School\",\n",
    "    \"BA\": \"Arts_Commerce_Management\",\n",
    "    \"MA\": \"Arts_Commerce_Management\",\n",
    "    \"B.Com\": \"Arts_Commerce_Management\",\n",
    "    \"M.Com\": \"Arts_Commerce_Management\",\n",
    "    \"BBA\": \"Arts_Commerce_Management\",\n",
    "    \"MBA\": \"Arts_Commerce_Management\",\n",
    "    \"BSc\": \"Science_IT\",\n",
    "    \"MSc\": \"Science_IT\",\n",
    "    \"BCA\": \"Science_IT\",\n",
    "    \"MCA\": \"Science_IT\",\n",
    "    \"BE\": \"Engineering_Architecture\",\n",
    "    \"B.Tech\": \"Engineering_Architecture\",\n",
    "    \"ME\": \"Engineering_Architecture\",\n",
    "    \"M.Tech\": \"Engineering_Architecture\",\n",
    "    \"B.Arch\": \"Engineering_Architecture\",\n",
    "    \"MBBS\": \"Medical_Pharma\",\n",
    "    \"MD\": \"Medical_Pharma\",\n",
    "    \"B.Pharm\": \"Medical_Pharma\",\n",
    "    \"M.Pharm\": \"Medical_Pharma\",\n",
    "    \"LLB\": \"Law_Education_Hospitality\",\n",
    "    \"LLM\": \"Law_Education_Hospitality\",\n",
    "    \"B.Ed\": \"Law_Education_Hospitality\",\n",
    "    \"M.Ed\": \"Law_Education_Hospitality\",\n",
    "    \"BHM\": \"Law_Education_Hospitality\",\n",
    "    \"MHM\": \"Law_Education_Hospitality\",\n",
    "    \"PhD\": \"Doctorate_Others\",\n",
    "    \"Others\": \"Doctorate_Others\"\n",
    "}\n",
    "\n",
    "city_to_region = {\n",
    "    \n",
    "    'Bangalore': 'South',\n",
    "    'Chennai': 'South',\n",
    "    'Hyderabad': 'South',\n",
    "    'Visakhapatnam': 'South',\n",
    "\n",
    "\n",
    "    'Srinagar': 'North',\n",
    "    'Varanasi': 'North',\n",
    "    'Jaipur': 'North',\n",
    "    'Lucknow': 'North',\n",
    "    'Meerut': 'North',\n",
    "    'Agra': 'North',\n",
    "    'Ghaziabad': 'North',\n",
    "    'Faridabad': 'North',\n",
    "    'Delhi': 'North',\n",
    "    'Kanpur': 'North',\n",
    "    'Patna': 'North',\n",
    "    'Ludhiana': 'North',\n",
    "\n",
    "\n",
    "    'Mumbai': 'West',\n",
    "    'Thane': 'West',\n",
    "    'Pune': 'West',\n",
    "    'Nashik': 'West',\n",
    "    'Vadodara': 'West',\n",
    "    'Kalyan': 'West',\n",
    "    'Rajkot': 'West',\n",
    "    'Ahmedabad': 'West',\n",
    "    'Surat': 'West',\n",
    "    'Indore': 'West',  \n",
    "\n",
    "    \n",
    "    'Kolkata': 'East',\n",
    "    \n",
    "    'Bhopal': 'Central',\n",
    "\n",
    "    'Unknown': 'Unknown'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "85f8f22f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Academic Pressure</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Study Satisfaction</th>\n",
       "      <th>Sleep Duration</th>\n",
       "      <th>Dietary Habits</th>\n",
       "      <th>Work/Study Hours</th>\n",
       "      <th>Financial Stress</th>\n",
       "      <th>Depression</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Suicidal_Thoughts</th>\n",
       "      <th>Family_Mental_Illness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.97</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.90</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.03</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.59</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.13</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Academic Pressure  CGPA  Study Satisfaction  Sleep Duration  \\\n",
       "0  33.0                5.0  8.97                 2.0               1   \n",
       "1  24.0                2.0  5.90                 5.0               1   \n",
       "2  31.0                3.0  7.03                 5.0               0   \n",
       "3  28.0                3.0  5.59                 2.0               2   \n",
       "4  25.0                4.0  8.13                 3.0               1   \n",
       "\n",
       "   Dietary Habits  Work/Study Hours  Financial Stress  Depression  Sex  \\\n",
       "0               2               3.0               1.0           1    1   \n",
       "1               1               3.0               2.0           0    0   \n",
       "2               2               9.0               1.0           0    1   \n",
       "3               1               4.0               5.0           1    0   \n",
       "4               1               1.0               1.0           0    0   \n",
       "\n",
       "   Suicidal_Thoughts  Family_Mental_Illness  \n",
       "0                  1                      0  \n",
       "1                  0                      1  \n",
       "2                  0                      1  \n",
       "3                  1                      1  \n",
       "4                  1                      0  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare 3 datasets to try logistic regression on to figure out how to deal with City and Degree. Base - drop region, Grouped - group and one hot encode, Freq - use frequency encoding\n",
    "df_base = df.copy()\n",
    "df_grouped = df.copy()\n",
    "df_freq = df.copy()\n",
    "\n",
    "df_base = df_base.drop(columns=['City', 'Degree'])\n",
    "df_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ace70bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to run logistic regression and tune hyperparameters\n",
    "def tune_logistic_regression(df, random_state=19):\n",
    "    \n",
    "    test_size = 0.2\n",
    "    scoring = 'roc_auc'\n",
    "    cv_folds = 5\n",
    "    \n",
    "    param_grid = {\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear', 'saga'],\n",
    "        'class_weight': [None, 'balanced'],\n",
    "        'max_iter': [1000]\n",
    "    }\n",
    "    \n",
    "    # Separate features and target\n",
    "    X = df.drop('Depression', axis=1)\n",
    "    y = df['Depression']\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Standardise features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_strategy = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    log_reg = LogisticRegression(random_state=random_state)\n",
    "    \n",
    "    # Grid search\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=log_reg,\n",
    "        param_grid=param_grid,\n",
    "        cv=cv_strategy,\n",
    "        scoring=scoring,\n",
    "        n_jobs=-1,\n",
    "        return_train_score=True\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    #Output results\n",
    "    results = {\n",
    "        'best_model': grid_search.best_estimator_,\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'best_score': grid_search.best_score_,\n",
    "        'grid_search': grid_search,\n",
    "        'X_train_scaled': X_train_scaled,\n",
    "        'X_test_scaled': X_test_scaled,\n",
    "        'y_train': y_train,\n",
    "        'y_test': y_test,\n",
    "        'scaler': scaler,\n",
    "        'feature_names': X.columns.tolist()\n",
    "    }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b86027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(results, plot=True):\n",
    "    \n",
    "    best_model = results['best_model']\n",
    "    X_test_scaled = results['X_test_scaled']\n",
    "    y_test = results['y_test']\n",
    "    feature_names = results['feature_names']\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = best_model.predict(X_test_scaled)\n",
    "    y_pred_proba = best_model.predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TEST SET EVALUATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['No Depression', 'Depression']))\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    print(f\"\\nROC-AUC Score: {roc_auc:.4f}\")\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    \n",
    "    if plot:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "        \n",
    "        # Confusion matrix heatmap\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0, 0],\n",
    "                    xticklabels=['No Depression', 'Depression'],\n",
    "                    yticklabels=['No Depression', 'Depression'])\n",
    "        axes[0, 0].set_title('Confusion Matrix')\n",
    "        axes[0, 0].set_ylabel('True Label')\n",
    "        axes[0, 0].set_xlabel('Predicted Label')\n",
    "        \n",
    "        # ROC curve\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "        axes[0, 1].plot(fpr, tpr, label=f'ROC (AUC={roc_auc:.4f})', linewidth=2)\n",
    "        axes[0, 1].plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "        axes[0, 1].set_xlabel('False Positive Rate')\n",
    "        axes[0, 1].set_ylabel('True Positive Rate')\n",
    "        axes[0, 1].set_title('ROC Curve')\n",
    "        axes[0, 1].legend()\n",
    "        axes[0, 1].grid(alpha=0.3)\n",
    "        \n",
    "        # Feature importance\n",
    "        coef_df = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'Coefficient': best_model.coef_[0]\n",
    "        }).sort_values('Coefficient', key=abs, ascending=False)\n",
    "        \n",
    "        axes[1, 0].barh(coef_df['Feature'], coef_df['Coefficient'])\n",
    "        axes[1, 0].set_xlabel('Coefficient Value')\n",
    "        axes[1, 0].set_title('Feature Importance')\n",
    "        axes[1, 0].axvline(x=0, color='black', linestyle='--', linewidth=0.8)\n",
    "        \n",
    "        # Cross Validation scores distribution\n",
    "        cv_results = results['grid_search'].cv_results_\n",
    "        axes[1, 1].hist(cv_results['mean_test_score'], bins=30, edgecolor='black', alpha=0.7)\n",
    "        axes[1, 1].axvline(results['best_score'], color='red', linestyle='--', \n",
    "                          linewidth=2, label=f'Best: {results[\"best_score\"]:.4f}')\n",
    "        axes[1, 1].set_xlabel('Mean CV Score')\n",
    "        axes[1, 1].set_ylabel('Frequency')\n",
    "        axes[1, 1].set_title('CV Scores Distribution')\n",
    "        axes[1, 1].legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return {\n",
    "        'y_pred': y_pred,\n",
    "        'y_pred_proba': y_pred_proba,\n",
    "        'roc_auc': roc_auc,\n",
    "        'confusion_matrix': cm\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f9c5d60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:\n",
      "{'C': 0.01, 'class_weight': 'balanced', 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "\n",
      "Best CV ROC-AUC Score: 0.9213\n",
      "\n",
      "============================================================\n",
      "TEST SET EVALUATION\n",
      "============================================================\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "No Depression       0.80      0.83      0.82      2310\n",
      "   Depression       0.88      0.86      0.87      3258\n",
      "\n",
      "     accuracy                           0.84      5568\n",
      "    macro avg       0.84      0.84      0.84      5568\n",
      " weighted avg       0.85      0.84      0.85      5568\n",
      "\n",
      "\n",
      "ROC-AUC Score: 0.9208\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1911  399]\n",
      " [ 465 2793]]\n"
     ]
    }
   ],
   "source": [
    "results = tune_logistic_regression(df_base)\n",
    "\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(results['best_params'])\n",
    "print(f\"\\nBest CV ROC-AUC Score: {results['best_score']:.4f}\")\n",
    "\n",
    "eval_results = evaluate_model(results, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4d20390e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map Degree and Region into broader groups\n",
    "df_grouped['Grouped_Degree']=df_grouped['Degree'].map(degree_category_map)\n",
    "#print(df_grouped['Grouped_Degree'].value_counts())\n",
    "df_grouped = df_grouped.drop(columns=['Degree'])\n",
    "\n",
    "df_grouped['Region']=df_grouped['City'].map(city_to_region)\n",
    "#print(df_grouped['Region'].value_counts())\n",
    "df_grouped = df_grouped.drop(columns=['City'])\n",
    "\n",
    "# One hot encode for each of the grouped variables\n",
    "df_grouped = pd.get_dummies(\n",
    "    df_grouped,\n",
    "    columns=['Grouped_Degree', 'Region'],\n",
    "    drop_first=True,\n",
    "    dtype=int\n",
    ")\n",
    "# df_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e89ef2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:\n",
      "{'C': 0.01, 'class_weight': 'balanced', 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "\n",
      "Best CV ROC-AUC Score: 0.9213\n",
      "\n",
      "============================================================\n",
      "TEST SET EVALUATION\n",
      "============================================================\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "No Depression       0.81      0.83      0.82      2310\n",
      "   Depression       0.87      0.86      0.87      3258\n",
      "\n",
      "     accuracy                           0.85      5568\n",
      "    macro avg       0.84      0.84      0.84      5568\n",
      " weighted avg       0.85      0.85      0.85      5568\n",
      "\n",
      "\n",
      "ROC-AUC Score: 0.9208\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1909  401]\n",
      " [ 456 2802]]\n"
     ]
    }
   ],
   "source": [
    "grouped_results = tune_logistic_regression(df_grouped)\n",
    "\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(results['best_params'])\n",
    "print(f\"\\nBest CV ROC-AUC Score: {grouped_results['best_score']:.4f}\")\n",
    "\n",
    "eval_results_grouped = evaluate_model(grouped_results, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5b71ac9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frequency encode Degree and Region\n",
    "degree_freq = df_freq['Degree'].value_counts(normalize=True)\n",
    "df_freq['Degree_freq'] = df_freq['Degree'].map(degree_freq)\n",
    "\n",
    "city_freq = df_freq['City'].value_counts(normalize=True)\n",
    "df_freq['City_freq'] = df_freq['City'].map(city_freq)\n",
    "\n",
    "df_freq = df_freq.drop(columns=['Degree', 'City'])\n",
    "# df_freq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "55d92dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:\n",
      "{'C': 0.01, 'class_weight': 'balanced', 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "\n",
      "Best CV ROC-AUC Score: 0.9213\n",
      "\n",
      "============================================================\n",
      "TEST SET EVALUATION\n",
      "============================================================\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "No Depression       0.84      0.78      0.81      2310\n",
      "   Depression       0.85      0.90      0.87      3258\n",
      "\n",
      "     accuracy                           0.85      5568\n",
      "    macro avg       0.85      0.84      0.84      5568\n",
      " weighted avg       0.85      0.85      0.85      5568\n",
      "\n",
      "\n",
      "ROC-AUC Score: 0.9209\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1813  497]\n",
      " [ 339 2919]]\n"
     ]
    }
   ],
   "source": [
    "freq_results = tune_logistic_regression(df_freq)\n",
    "\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(results['best_params'])\n",
    "print(f\"\\nBest CV ROC-AUC Score: {freq_results['best_score']:.4f}\")\n",
    "\n",
    "eval_results_grouped = evaluate_model(freq_results, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613bb2a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
